{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "import os\n",
    "import time\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "# https://nbviewer.jupyter.org/github/kaushaltrivedi/bert-toxic-comments-multilabel/blob/master/toxic-bert-multilabel-classification.ipynb?source=post_page-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WD = os.getcwd()\n",
    "DATA_DIR = os.path.join(WD, 'data','mpst-movie-plot-synopses-with-tags','mpst_full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14828, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_DIR)\n",
    "data = data.drop(['synopsis_source'],axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0057603</td>\n",
       "      <td>I tre volti della paura</td>\n",
       "      <td>Note: this synopsis is for the orginal Italian...</td>\n",
       "      <td>cult, horror, gothic, murder, atmospheric</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1733125</td>\n",
       "      <td>Dungeons &amp; Dragons: The Book of Vile Darkness</td>\n",
       "      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n",
       "      <td>violence</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0033045</td>\n",
       "      <td>The Shop Around the Corner</td>\n",
       "      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0113862</td>\n",
       "      <td>Mr. Holland's Opus</td>\n",
       "      <td>Glenn Holland, not a morning person by anyone'...</td>\n",
       "      <td>inspiring, romantic, stupid, feel-good</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0086250</td>\n",
       "      <td>Scarface</td>\n",
       "      <td>In May 1980, a Cuban man named Tony Montana (A...</td>\n",
       "      <td>cruelty, murder, dramatic, cult, violence, atm...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     imdb_id                                          title  \\\n",
       "0  tt0057603                        I tre volti della paura   \n",
       "1  tt1733125  Dungeons & Dragons: The Book of Vile Darkness   \n",
       "2  tt0033045                     The Shop Around the Corner   \n",
       "3  tt0113862                             Mr. Holland's Opus   \n",
       "4  tt0086250                                       Scarface   \n",
       "\n",
       "                                       plot_synopsis  \\\n",
       "0  Note: this synopsis is for the orginal Italian...   \n",
       "1  Two thousand years ago, Nhagruul the Foul, a s...   \n",
       "2  Matuschek's, a gift store in Budapest, is the ...   \n",
       "3  Glenn Holland, not a morning person by anyone'...   \n",
       "4  In May 1980, a Cuban man named Tony Montana (A...   \n",
       "\n",
       "                                                tags  split  \n",
       "0          cult, horror, gothic, murder, atmospheric  train  \n",
       "1                                           violence  train  \n",
       "2                                           romantic   test  \n",
       "3             inspiring, romantic, stupid, feel-good  train  \n",
       "4  cruelty, murder, dramatic, cult, violence, atm...    val  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = data['tags'].str.split(', ')\n",
    "lens = split.str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cult' 'horror' 'gothic' 'murder' 'atmospheric' 'violence' 'romantic'\n",
      " 'inspiring' 'stupid' 'feel-good' 'cruelty' 'dramatic' 'action' 'revenge'\n",
      " 'sadist' 'queer' 'flashback' 'mystery' 'suspenseful' 'neo noir' 'prank'\n",
      " 'psychedelic' 'tragedy' 'autobiographical' 'home movie'\n",
      " 'good versus evil' 'depressing' 'realism' 'boring' 'haunting'\n",
      " 'sentimental' 'paranormal' 'historical' 'storytelling' 'comedy' 'fantasy'\n",
      " 'philosophical' 'adult comedy' 'cute' 'entertaining' 'bleak' 'humor'\n",
      " 'plot twist' 'christian film' 'pornographic' 'insanity' 'brainwashing'\n",
      " 'sci-fi' 'dark' 'claustrophobic' 'psychological' 'melodrama'\n",
      " 'historical fiction' 'absurd' 'satire' 'alternate reality'\n",
      " 'alternate history' 'comic' 'grindhouse film' 'thought-provoking'\n",
      " 'clever' 'western' 'blaxploitation' 'whimsical' 'intrigue' 'allegory'\n",
      " 'anti war' 'avant garde' 'suicidal' 'magical realism' 'non fiction']\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "temp_df = pd.DataFrame({'imdb_id': np.repeat(data['imdb_id'].values, lens), \n",
    "                        'category': np.concatenate(split),\n",
    "                       'values': 1})\n",
    "\n",
    "print(temp_df['category'].unique())\n",
    "print(len(temp_df['category'].unique()))\n",
    "\n",
    "temp_df = temp_df.pivot(index='imdb_id', columns='category', values='values').fillna(0).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>absurd</th>\n",
       "      <th>action</th>\n",
       "      <th>adult comedy</th>\n",
       "      <th>allegory</th>\n",
       "      <th>alternate history</th>\n",
       "      <th>...</th>\n",
       "      <th>sentimental</th>\n",
       "      <th>storytelling</th>\n",
       "      <th>stupid</th>\n",
       "      <th>suicidal</th>\n",
       "      <th>suspenseful</th>\n",
       "      <th>thought-provoking</th>\n",
       "      <th>tragedy</th>\n",
       "      <th>violence</th>\n",
       "      <th>western</th>\n",
       "      <th>whimsical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0057603</td>\n",
       "      <td>I tre volti della paura</td>\n",
       "      <td>Note: this synopsis is for the orginal Italian...</td>\n",
       "      <td>cult, horror, gothic, murder, atmospheric</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1733125</td>\n",
       "      <td>Dungeons &amp; Dragons: The Book of Vile Darkness</td>\n",
       "      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n",
       "      <td>violence</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0033045</td>\n",
       "      <td>The Shop Around the Corner</td>\n",
       "      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n",
       "      <td>romantic</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0113862</td>\n",
       "      <td>Mr. Holland's Opus</td>\n",
       "      <td>Glenn Holland, not a morning person by anyone'...</td>\n",
       "      <td>inspiring, romantic, stupid, feel-good</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0086250</td>\n",
       "      <td>Scarface</td>\n",
       "      <td>In May 1980, a Cuban man named Tony Montana (A...</td>\n",
       "      <td>cruelty, murder, dramatic, cult, violence, atm...</td>\n",
       "      <td>val</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     imdb_id                                          title  \\\n",
       "0  tt0057603                        I tre volti della paura   \n",
       "1  tt1733125  Dungeons & Dragons: The Book of Vile Darkness   \n",
       "2  tt0033045                     The Shop Around the Corner   \n",
       "3  tt0113862                             Mr. Holland's Opus   \n",
       "4  tt0086250                                       Scarface   \n",
       "\n",
       "                                       plot_synopsis  \\\n",
       "0  Note: this synopsis is for the orginal Italian...   \n",
       "1  Two thousand years ago, Nhagruul the Foul, a s...   \n",
       "2  Matuschek's, a gift store in Budapest, is the ...   \n",
       "3  Glenn Holland, not a morning person by anyone'...   \n",
       "4  In May 1980, a Cuban man named Tony Montana (A...   \n",
       "\n",
       "                                                tags  split  absurd  action  \\\n",
       "0          cult, horror, gothic, murder, atmospheric  train     0.0     0.0   \n",
       "1                                           violence  train     0.0     0.0   \n",
       "2                                           romantic   test     0.0     0.0   \n",
       "3             inspiring, romantic, stupid, feel-good  train     0.0     0.0   \n",
       "4  cruelty, murder, dramatic, cult, violence, atm...    val     0.0     1.0   \n",
       "\n",
       "   adult comedy  allegory  alternate history  ...  sentimental  storytelling  \\\n",
       "0           0.0       0.0                0.0  ...          0.0           0.0   \n",
       "1           0.0       0.0                0.0  ...          0.0           0.0   \n",
       "2           0.0       0.0                0.0  ...          0.0           0.0   \n",
       "3           0.0       0.0                0.0  ...          0.0           0.0   \n",
       "4           0.0       0.0                0.0  ...          0.0           0.0   \n",
       "\n",
       "   stupid  suicidal  suspenseful  thought-provoking  tragedy  violence  \\\n",
       "0     0.0       0.0          0.0                0.0      0.0       0.0   \n",
       "1     0.0       0.0          0.0                0.0      0.0       1.0   \n",
       "2     0.0       0.0          0.0                0.0      0.0       0.0   \n",
       "3     1.0       0.0          0.0                0.0      0.0       0.0   \n",
       "4     0.0       0.0          0.0                0.0      0.0       1.0   \n",
       "\n",
       "   western  whimsical  \n",
       "0      0.0        0.0  \n",
       "1      0.0        0.0  \n",
       "2      0.0        0.0  \n",
       "3      0.0        0.0  \n",
       "4      0.0        0.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_separate = data.merge(temp_df, how='left', on='imdb_id')\n",
    "data_separate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9489, 76), (2373, 76), (2966, 76))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = data_separate[data_separate['split'] == 'train']\n",
    "val_df = data_separate[data_separate['split'] == 'val']\n",
    "test_df = data_separate[data_separate['split'] == 'test']\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip()\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 1 # 0 is reserved for none\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        sentence = clean_str(sentence)\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding=\"utf8\")\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 121301\n"
     ]
    }
   ],
   "source": [
    "# build vocab\n",
    "vocab = Vocab()\n",
    "for i in train_df['plot_synopsis']:\n",
    "    vocab.addSentence(i)\n",
    "print('Vocab Size:', vocab.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "# build word embeddings\n",
    "glove = loadGloveModel(os.path.join(WD,'glove.6B','glove.6B.300d.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create token-embedding mapping\n",
    "weights_matrix = np.zeros((vocab.n_words+1, 300))\n",
    "for word, i in vocab.word2index.items():\n",
    "    if word in glove:\n",
    "        weights_matrix[i] = glove[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from pytorch_transformers import *\n",
    "# from pytorch_transformers.modeling_bert import BertPreTrainedModel\n",
    "# from pytorch_transformers.optimization import AdamW\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPSTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, max_seq_length, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def prepare_sample_features(self, sample):\n",
    "        sample_clean = clean_str(sample)\n",
    "        \n",
    "        tokenized_sample = sample_clean.split(' ')[:self.max_seq_length]\n",
    "        \n",
    "        \n",
    "    \n",
    "        input_ids = [vocab.word2index[x] if (x in vocab.word2index) else 0 for x in tokenized_sample]\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (self.max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        \n",
    "        assert len(input_ids) == self.max_seq_length\n",
    "        \n",
    "        return input_ids\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataframe.iloc[idx]['plot_synopsis']\n",
    "        label = self.dataframe.iloc[idx][5:]\n",
    "        \n",
    "        input_ids = self.prepare_sample_features(sample)\n",
    "        \n",
    "        return torch.tensor(input_ids), torch.tensor(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XML_CNN(torch.nn.Module):\n",
    "    def __init__(self, weights_matrix, label_size=71):\n",
    "        super(XML_CNN, self).__init__()\n",
    "        weight_tensor = torch.tensor(weights_matrix)\n",
    "        num_embeddings, embedding_dim = weight_tensor.size()\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.embedding.load_state_dict({'weight': weight_tensor})\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.cnnk2 = torch.nn.Conv2d(1,3,(2,embedding_dim))\n",
    "        self.cnnk4 = torch.nn.Conv2d(1,3,(4,embedding_dim))\n",
    "        self.cnnk8 = torch.nn.Conv2d(1,3,(8,embedding_dim))\n",
    "        \n",
    "        self.linear = torch.nn.Linear(2989, 512)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.output = torch.nn.Linear(512,label_size)\n",
    "        \n",
    "    def kmax_pooling(self, x, dim, k):\n",
    "        index = x.topk(k, dim = dim)[1].sort(dim = dim)[0]\n",
    "        return x.gather(dim, index)\n",
    "    \n",
    "    def conv_and_pool(self, conv, x):\n",
    "        x = F.relu(conv(x)).squeeze(3)\n",
    "        B, C, W = x.size() \n",
    "        x = self.kmax_pooling(x.view(B,-1), dim = 1, k=(C*W)//3)\n",
    "        return(x)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x) #  (N, W, D)\n",
    "#         print(x.size())\n",
    "        x = x.unsqueeze(1) # (N, Ci, W, D)\n",
    "        \n",
    "        x2 = self.conv_and_pool(self.cnnk2, x) # (B, W)\n",
    "        x4 = self.conv_and_pool(self.cnnk4, x)\n",
    "        x8 = self.conv_and_pool(self.cnnk8, x)\n",
    "        \n",
    "        x = torch.cat([x2,x4,x8],1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.linear(x))\n",
    "        x = self.output(x)\n",
    "\n",
    "#         print('cnn2', x2.size())\n",
    "#         print('cnn4', x4.size())\n",
    "#         print('cnn8', x8.size())\n",
    "        return(x)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric\n",
    "def precision_k(pred, label, k=[1, 3, 5]):\n",
    "    batch_size = pred.shape[0]\n",
    "    \n",
    "    precision = []\n",
    "    for _k in k:\n",
    "        p = 0\n",
    "        for i in range(batch_size):\n",
    "            p += label[i, pred[i, :_k]].mean()\n",
    "        precision.append(p*100/batch_size)\n",
    "    \n",
    "    return precision\n",
    "\n",
    "def ndcg_k(pred, label, k=[1, 3, 5]):\n",
    "    batch_size = pred.shape[0]\n",
    "    \n",
    "    ndcg = []\n",
    "    for _k in k:\n",
    "        score = 0\n",
    "        rank = np.log2(np.arange(2, 2 + _k))\n",
    "        for i in range(batch_size):\n",
    "            l = label[i, pred[i, :_k]]\n",
    "            n = l.sum()\n",
    "            if(n == 0):\n",
    "                continue\n",
    "            \n",
    "            dcg = (l/rank).sum()\n",
    "            label_count = label[i].sum()\n",
    "            norm = 1 / np.log2(np.arange(2, 2 + np.min((_k, label_count))))\n",
    "            norm = norm.sum()\n",
    "            score += dcg/norm\n",
    "            \n",
    "        ndcg.append(score*100/batch_size)\n",
    "    \n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloaders, model, optimizer, criterion, scheduler, num_epochs=2):\n",
    "    since = time.time()\n",
    "    step_sizes = {'train': len(dataloaders['train']), \n",
    "                     'valid': len(dataloaders['valid'])}\n",
    "    \n",
    "    weight = torch.tensor([0.5, 1.5])\n",
    "\n",
    "    for epoch in tnrange(int(num_epochs), desc=\"Epoch\"):\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0\n",
    "            running_acc = 0\n",
    "            \n",
    "            r_p1, r_p3, r_p5 = 0,0,0\n",
    "            r_ndcg1, r_ndcg3, r_ndcg5 = 0,0,0\n",
    "        \n",
    "            for step, batch in enumerate(tqdm_notebook(dataloaders[phase], desc=phase)):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                input_ids, label_ids = batch\n",
    "                \n",
    "                logits = model(input_ids)\n",
    "                sigmoid = logits.sigmoid()\n",
    "\n",
    "                loss = criterion(sigmoid, label_ids)\n",
    "                \n",
    "#                 label_weight = weight[label_ids.data.view(-1).long()].view_as(label_ids).to(device)\n",
    "#                 weighted_loss = loss * label_weight\n",
    "#                 weighted_loss_average = weighted_loss.mean()\n",
    "#                 running_loss += weighted_loss_average.item()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "#                 sigmoid_numpy = sigmoid.detach().cpu().numpy()\n",
    "#                 labels_numpy = label_ids.detach().cpu().numpy()\n",
    "#                 acc = jaccard_score(labels_numpy, sigmoid_numpy.round(), average='samples')\n",
    "#                 running_acc += acc\n",
    "#                 print(weighted_loss_average.item(), acc, sigmoid_numpy.round().sum(axis=1))\n",
    "\n",
    "               \n",
    "\n",
    "                logits_cpu = logits.data.cpu()\n",
    "                labels_cpu = label_ids.data.cpu()\n",
    "            \n",
    "#                 print(logits_cpu.topk(k=5)[0].numpy())\n",
    "#                 print(logits_cpu.topk(k=5)[1].numpy())\n",
    "            \n",
    "                _p1,_p3,_p5=precision_k(logits_cpu.topk(k=5)[1].numpy(), labels_cpu.numpy(), k=[1,3,5])\n",
    "                r_p1+= _p1\n",
    "                r_p3+= _p3\n",
    "                r_p5+= _p5\n",
    "                \n",
    "                _ndcg1,_ndcg3,_ndcg5=ndcg_k(logits_cpu.topk(k=5)[1].numpy(), labels_cpu.numpy(), k=[1,3,5])\n",
    "                r_ndcg1 += _ndcg1\n",
    "                r_ndcg3 += _ndcg3\n",
    "                r_ndcg5 += _ndcg5\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "#                     scheduler.step()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss = running_loss / step_sizes[phase]\n",
    "                \n",
    "                r_p1 = r_p1 / step_sizes[phase]\n",
    "                r_p3 = r_p3 / step_sizes[phase]\n",
    "                r_p5 = r_p5 / step_sizes[phase]\n",
    "                \n",
    "                r_ndcg1 = r_ndcg1 / step_sizes[phase]\n",
    "                r_ndcg3= r_ndcg3 / step_sizes[phase]\n",
    "                r_ndcg5 = r_ndcg5 / step_sizes[phase]\n",
    "                \n",
    "                print(\"precision@1 : %.4f , precision@3 : %.4f , precision@5 : %.4f \"%(r_p1,r_p3,r_p5))\n",
    "                print(\"ndcg@1 : %.4f , ndcg@3 : %.4f , ndcg@5 : %.4f \"%(r_ndcg1,r_ndcg3,r_ndcg5))\n",
    "            else:\n",
    "                valid_loss = running_loss / step_sizes[phase]\n",
    "                \n",
    "                r_p1 = r_p1 / step_sizes[phase]\n",
    "                r_p3 = r_p3 / step_sizes[phase]\n",
    "                r_p5 = r_p5 / step_sizes[phase]\n",
    "                \n",
    "                r_ndcg1 = r_ndcg1 / step_sizes[phase]\n",
    "                r_ndcg3= r_ndcg3 / step_sizes[phase]\n",
    "                r_ndcg5 = r_ndcg5 / step_sizes[phase]\n",
    "                \n",
    "                print(\"precision@1 : %.4f , precision@3 : %.4f , precision@5 : %.4f \"%(r_p1,r_p3,r_p5))\n",
    "                print(\"ndcg@1 : %.4f , ndcg@3 : %.4f , ndcg@5 : %.4f \"%(r_ndcg1,r_ndcg3,r_ndcg5))\n",
    "\n",
    "                \n",
    "        print('Epoch [{}/{}] train loss: {:.4f} valid loss: {:.4f} '.format(\n",
    "                epoch+1, num_epochs,train_loss, valid_loss))\n",
    "                \n",
    "\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MPSTDataset(train_df, 1000)\n",
    "train_dl = DataLoader(train_ds,batch_size=32, shuffle=True)\n",
    "\n",
    "val_ds = MPSTDataset(val_df, 1000)\n",
    "val_dl = DataLoader(val_ds,batch_size=32, shuffle=True)\n",
    "\n",
    "dloaders = {'train':train_dl, 'valid':val_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willi\\AppData\\Local\\Continuum\\miniconda3\\envs\\main\\lib\\site-packages\\torch\\nn\\_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = XML_CNN(weights_matrix=weights_matrix)\n",
    "model.to(device)\n",
    "criterion = torch.nn.BCELoss(reduce=True)\n",
    "\n",
    "# optimizer = torch.optim.Adamax(model.parameters(), lr=0.001)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3833457a788451f821eb111bc53b912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e89af1c61e241d2a698577f79af672c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=297, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 36.9256 , precision@3 : 28.9158 , precision@5 : 24.2293 \n",
      "ndcg@1 : 36.9256 , ndcg@3 : 38.2709 , ndcg@5 : 41.3068 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc22ab9bf6b4060b86fbfe88b599dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=75, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 40.3500 , precision@3 : 31.7250 , precision@5 : 25.8017 \n",
      "ndcg@1 : 40.3500 , ndcg@3 : 42.3261 , ndcg@5 : 44.7706 \n",
      "Epoch [1/10] train loss: 0.0810 valid loss: 0.0750 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f9c5870d8f4c9583d42e018808ce67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=297, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 41.0979 , precision@3 : 31.3305 , precision@5 : 25.9143 \n",
      "ndcg@1 : 41.0979 , ndcg@3 : 42.5119 , ndcg@5 : 45.4195 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9388ad46c8426aabfd296807d29db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=75, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 39.9250 , precision@3 : 30.3194 , precision@5 : 25.9650 \n",
      "ndcg@1 : 39.9250 , ndcg@3 : 40.1382 , ndcg@5 : 43.7190 \n",
      "Epoch [2/10] train loss: 0.0737 valid loss: 0.0754 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72c6ce8dd73419b991350a2cd7de209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=297, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 43.2350 , precision@3 : 32.6135 , precision@5 : 26.5726 \n",
      "ndcg@1 : 43.2350 , ndcg@3 : 44.6177 , ndcg@5 : 47.3390 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f55b1e21c274b2983100f4656a2ccc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=75, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 47.8833 , precision@3 : 33.7778 , precision@5 : 27.3533 \n",
      "ndcg@1 : 47.8833 , ndcg@3 : 47.1790 , ndcg@5 : 49.8195 \n",
      "Epoch [3/10] train loss: 0.0721 valid loss: 0.0725 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f19c5bbba314d39a654458b4d16714e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=297, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 46.6522 , precision@3 : 33.9547 , precision@5 : 27.2309 \n",
      "ndcg@1 : 46.6522 , ndcg@3 : 47.0140 , ndcg@5 : 49.3582 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2d17e980fa42ec829f8db128876326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=75, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 47.0750 , precision@3 : 33.5444 , precision@5 : 27.2850 \n",
      "ndcg@1 : 47.0750 , ndcg@3 : 46.8793 , ndcg@5 : 49.6336 \n",
      "Epoch [4/10] train loss: 0.0707 valid loss: 0.0725 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f619eb90e1044a579e3d917e7e741179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=297, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 48.4972 , precision@3 : 34.9164 , precision@5 : 27.8133 \n",
      "ndcg@1 : 48.4972 , ndcg@3 : 48.6566 , ndcg@5 : 50.8335 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a495a2cc3e944614be14a2328fa493d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=75, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 47.9917 , precision@3 : 34.7167 , precision@5 : 27.9450 \n",
      "ndcg@1 : 47.9917 , ndcg@3 : 47.9699 , ndcg@5 : 50.4864 \n",
      "Epoch [5/10] train loss: 0.0692 valid loss: 0.0727 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d97b81bf2d41b1857a37a6f3fece91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=297, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 49.9164 , precision@3 : 35.9050 , precision@5 : 28.7127 \n",
      "ndcg@1 : 49.9164 , ndcg@3 : 49.8788 , ndcg@5 : 52.3346 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47787e183ee64f67b2a6c7bb3fa16c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=75, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 47.4667 , precision@3 : 34.1444 , precision@5 : 27.3267 \n",
      "ndcg@1 : 47.4667 , ndcg@3 : 47.2537 , ndcg@5 : 49.6044 \n",
      "Epoch [6/10] train loss: 0.0673 valid loss: 0.0727 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ba8bf1c7e34fd48da62b4c471f55fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=297, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 51.2422 , precision@3 : 36.8551 , precision@5 : 29.4816 \n",
      "ndcg@1 : 51.2422 , ndcg@3 : 51.2850 , ndcg@5 : 53.7394 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdf332874974b1ea42658b4a46ccac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=75, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 49.6583 , precision@3 : 34.3472 , precision@5 : 27.2733 \n",
      "ndcg@1 : 49.6583 , ndcg@3 : 48.1743 , ndcg@5 : 50.3248 \n",
      "Epoch [7/10] train loss: 0.0651 valid loss: 0.0738 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fe44de70d346f18918931cfa4dab6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=297, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 51.9131 , precision@3 : 37.8086 , precision@5 : 30.3233 \n",
      "ndcg@1 : 51.9131 , ndcg@3 : 52.4049 , ndcg@5 : 54.9959 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c68a87c01024c76b659bfe84733d8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=75, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 49.4500 , precision@3 : 34.1028 , precision@5 : 27.0400 \n",
      "ndcg@1 : 49.4500 , ndcg@3 : 48.1710 , ndcg@5 : 50.2875 \n",
      "Epoch [8/10] train loss: 0.0631 valid loss: 0.0747 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad72e63d93f41c38c068fe6443a861b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=297, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 53.4097 , precision@3 : 38.9817 , precision@5 : 31.3131 \n",
      "ndcg@1 : 53.4097 , ndcg@3 : 53.8931 , ndcg@5 : 56.4740 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6f456ff5d24165aaf8bcf02313e9f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=75, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 48.1417 , precision@3 : 33.9194 , precision@5 : 27.0467 \n",
      "ndcg@1 : 48.1417 , ndcg@3 : 47.3307 , ndcg@5 : 49.7012 \n",
      "Epoch [9/10] train loss: 0.0604 valid loss: 0.0754 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deff8389eefe4fb98984caa7559aac39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=297, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 55.8929 , precision@3 : 40.2353 , precision@5 : 32.3131 \n",
      "ndcg@1 : 55.8929 , ndcg@3 : 56.0303 , ndcg@5 : 58.7521 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e7a54c1b454d42b6950badd4848bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid', max=75, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 47.9250 , precision@3 : 33.2917 , precision@5 : 26.4667 \n",
      "ndcg@1 : 47.9250 , ndcg@3 : 46.8679 , ndcg@5 : 49.0094 \n",
      "Epoch [10/10] train loss: 0.0583 valid loss: 0.0767 \n",
      "Training time:   5.166269 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = train_model(dloaders, model, optimizer,criterion, scheduler=None, num_epochs=10)\n",
    "print('Training time: {:10f} minutes'.format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = MPSTDataset(test_df, 1000)\n",
    "test_dl = DataLoader(test_ds,batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = iter(test_dl).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21643,    38,     6,  ...,  1539,  5562,    38],\n",
       "        [  162,   369,     6,  ...,     0,     0,     0],\n",
       "        [  607,     6,   201,  ...,  2654,    35,   140]])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[ 0.1738,  0.0228, -0.6677, -1.2264, -1.4117],\n",
       "        [-1.0175, -1.3914, -1.7474, -2.2155, -2.3684],\n",
       "        [-0.0828, -0.1114, -0.2452, -0.2955, -0.8152]], device='cuda:0',\n",
       "       grad_fn=<TopkBackward>),\n",
       "indices=tensor([[43, 68, 56, 17,  1],\n",
       "        [43, 68, 28, 57, 52],\n",
       "        [20, 43, 68, 17, 57]], device='cuda:0'))"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(test_sample[0].to(device)).topk(5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-442-f874a113e261>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m test_sample[1][[[43, 68, 56, 17,  1],\n\u001b[0;32m      2\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[1;36m43\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m68\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m57\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m52\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         [20, 43, 68, 17, 57]]]\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "test_sample[1][[[43, 68, 56, 17,  1],\n",
    "        [43, 68, 28, 57, 52],\n",
    "        [20, 43, 68, 17, 57]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([43, 68, 20, 17,  1], device='cuda:0')"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample[1][1][[43, 68, 28, 57, 52]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
